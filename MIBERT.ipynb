{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlsrRRf3SqE-"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import itertools\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pympler import asizeof\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import IPython.display # IPython.display for audio output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGfXC68SSr3p"
   },
   "outputs": [],
   "source": [
    "# tensorize preprocessed files (Dataset, DataLoader)\n",
    "def volume_check(waves, specs, threshold=10):\n",
    "    \"\"\"\n",
    "    threshold : threshold of data block. unit : GB\n",
    "    \"\"\"\n",
    "    # TODO : check whether volume of waves & specs under threshold.\n",
    "    if asizeof.asizeof(waves) + asizeof.asizeof(specs) > threshold * 2**30:    \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class MIBERT_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for MIBERT\n",
    "    : [ wave, masked_wave, mel_spectrogram, masked_mel_spectrogram, boundaries, labels, ... ]\n",
    "    each sample shape info\n",
    "    : wave : [hop_length * k]\n",
    "    : spectrogram : [n_mels, k+1] if center = True, else  [n_mels, k + 1 - n_fft/hop_length ]\n",
    "    : boundaries : [ num_seg + 1 ]\n",
    "    : labels : [ num_seg ]\n",
    "    : seg_nums : int\n",
    "    : masking_indice : [ int(masking_ratio * len(set(labels))) ]\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, meta_csv, config, transform=None):\n",
    "        self.df = pd.read_csv(meta_csv)\n",
    "        self.columns = self.df.columns\n",
    "        self.transform = transform\n",
    "\n",
    "        self.waves, self.specs, self.masked_waves, self.masked_specs = [], [], [], []\n",
    "        self.boundaries_collection, self.labels_collection, self.seg_nums, self.masking_indice = [], [], [], []\n",
    "        for i in range(len(self.df)): # TODO : Random selection?\n",
    "            if volume_check(waves, specs, config['data_block_threshold']): # TODO pseudo volume check using waves and spectrograms.  \n",
    "                unit = self.df.iloc[i]\n",
    "                cropped_wave_path, mel_spectrogram_path = unit[2], unit[3]\n",
    "                if len(unit) == 6:\n",
    "                    # case : using single feature and single algorithm of msaf\n",
    "                    maksed_wave_path, masked_other_path = unit[4], unit[5]\n",
    "                    \n",
    "                    cropped_wave = librosa.load(cropped_wave_path, sr=config['sr']) \n",
    "                    masked_wave = librosa.load(masked_wave_path, sr=config['sr'])\n",
    "                    \n",
    "                    with open(mel_spectrogram_path, 'rb') as f:\n",
    "                        mel_spec = pickle.load(f)\n",
    "                    with open(masked_other_path, 'rb') as f:\n",
    "                        maksed_spec, boundaries, labels, seg_num, masking_index = pickle.load(f)\n",
    "                    \n",
    "                    self.waves.append(cropped_wave)\n",
    "                    self.specs.append(mel_spec)\n",
    "                    self.masked_waves.append(masked_wave)\n",
    "                    self.masked_specs.append(maksed_spec)\n",
    "                    self.boundaries_collection.append(boundaries)\n",
    "                    self.labels_collection.append(labels)\n",
    "                    self.seg_nums.append(seg_num)\n",
    "                    self.masking_indice.append(masking_index)                    \n",
    "                else:\n",
    "                    # case : using multiple features & algorithms of msaf\n",
    "                    # TODO : \n",
    "                    pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.waves)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = {\n",
    "            'wave' : self.waves[idx],\n",
    "            'spec' : self.specs[idx],\n",
    "            'masked_wave' : self.masked_waves[idx],\n",
    "            'masked_spec' : self.masked_specs[idx],\n",
    "            'boundaries' : self.boundaries_collection[idx],\n",
    "            'labels' : self.labels_collection[idx],\n",
    "            'seg_num' : self.seg_nums,\n",
    "            'masking_idx' : self.masking_indice[idx]\n",
    "        }\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample \n",
    "\n",
    "# mibert_trn_dataset = MIBERT_Dataset('./meta.csv',config)\n",
    "# mibert_tst_dataset = MIBERT_Dataset('./meta.csv',config)\n",
    "\n",
    "# trn_mibert_dataloader = DataLoader(mibert_trn_dataset, batch_size = config['batch_size'], drop_last=True)\n",
    "# tst_mibert_dataloader = DataLoader(mibert_tst_dataset, batch_size = config['batch_size'], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOQmE15NkRsn"
   },
   "outputs": [],
   "source": [
    "def tensorize_padding_batch(input, mode = 'wave', n_mels = 128):\n",
    "    \"\"\"\n",
    "    input is wave(dim=2, [batch_size, hop_length * k ] ) or spectrogram(dim=3, [ batch_size, n_mels, k+1 ]).\n",
    "    k is different among batch samples.\n",
    "    mode is flag whether 'wave' or 'spec'\n",
    "    \"\"\"\n",
    "    real_length = [sample.shape[-1] for sample in input]\n",
    "    max_length = max(real_length)\n",
    "    \n",
    "    pad_size = 1 if mode is 'wave' else n_mels\n",
    "    reshape_size = -1 if mode is 'wave' else [n_mels, -1]\n",
    "    zero_pad = [0] * pad_size\n",
    "\n",
    "    padded_input = np.array(\n",
    "        [np.concatenate(\n",
    "            (sample, np.tile(zero_pad, max_length - sample.shape[-1]).reshape(reshape_size))\n",
    "            , axis= -1\n",
    "            ) for sample in input ]\n",
    "        )\n",
    "    return torch.from_numpy(padded_input).float(), real_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHreobqhk-A3"
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "class FramizationCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FramizationCNN, self).__init__()\n",
    "        # feature = config['FramizationCNN']['feature']\n",
    "        feature = 128\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1, out_channels = feature, kernel_size = 128, stride =64 , padding = 64, bias = False)\n",
    "        self.conv2 = nn.Conv1d(in_channels = feature, out_channels = feature, kernel_size = 128, stride = 2, padding = 64, bias = False)\n",
    "        self.conv3 = nn.Conv1d(in_channels = feature, out_channels = feature, kernel_size = 128, stride = 2, padding = 64, bias = False)\n",
    "        self.conv4 = nn.Conv1d(in_channels = feature, out_channels = feature, kernel_size = 256, stride = 2, padding = 128, bias = False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(feature)\n",
    "        self.bn2 = nn.BatchNorm1d(feature)\n",
    "        self.bn3 = nn.BatchNorm1d(feature)\n",
    "        self.bn4 = nn.BatchNorm1d(feature)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_layer(self.conv3)\n",
    "        init_layer(self.conv4)\n",
    "\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "        init_bn(self.bn3)\n",
    "        init_bn(self.bn4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        x = F.relu_(self.bn3(self.conv3(x)))\n",
    "        x = self.bn4(self.conv4(x))\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JADbsKkyljJP"
   },
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"Implementation of the gelu activation function by Hugging Face\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "    \n",
    "class FramewiseFC(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FramewiseFC, self).__init__()\n",
    "        layer_params = config['FraemwiseFC']\n",
    "        self.fc1 = nn.Linear(layer_params['fc1_in_dim'], layer_params['fc1_out_dim'])\n",
    "        self.fc2 = nn.Linear(layer_params['fc2_in_dim'], layer_params['fc2_out_dim'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4mmbPeeQ9qp"
   },
   "outputs": [],
   "source": [
    "def time2frame(t, sr=22050, hop_length=512):\n",
    "    return t * sr / hop_length\n",
    "\n",
    "# TODO : to modify batch version for speed up - need for optimization\n",
    "def segment_pooling(frames, boundaries_batch, real_len, config, mode='max'):\n",
    "    \"\"\"\n",
    "    pooling by segment according to boundaries/labels of msaf\n",
    "    < input >\n",
    "    frames : [batch_size, num_frames, feature]\n",
    "    boundaries : [batch_size, num_boundaries]\n",
    "    real_len : [batch_size] unit : frame\n",
    "    mode : pooling mode. ex) 'max' : max-pooling / 'avg' : average-pooling / ...\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO : real segment zero-padding according to config['num_segment'] \n",
    "    # BERT에서 어떻게 처리하는지 알아보기.\n",
    "\n",
    "    result = []\n",
    "    if mode == 'max':\n",
    "        pool_func = torch.max\n",
    "    if mode == 'avg':\n",
    "        pool_func = torch.mean\n",
    "        \n",
    "    for idx, boundaries in enumerate(boundaries_batch):\n",
    "        batch_buffer = []\n",
    "        for start, end in zip(boundaries[:-1], boundaries[1:]):\n",
    "            batch_buffer.append(pool_func(frames[idx, math.floor(time2frame(start)):math.ceil(time2frame(end))], axis=0).values) # [feature]\n",
    "        result.append(torch.stack(batch_buffer))\n",
    "    return torch.stack(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9feMTXwIhgvf"
   },
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "def split_last(x, shape):\n",
    "    \"split the last dimension to given shape\"\n",
    "    shape = list(shape)\n",
    "    assert shape.count(-1) <= 1\n",
    "    if -1 in shape:\n",
    "        shape[shape.index(-1)] = int(x.size(-1) / -np.prod(shape))\n",
    "    return x.view(*x.size()[:-1], *shape)\n",
    "\n",
    "def merge_last(x, n_dims):\n",
    "    \"merge the last n_dims to a dimension\"\n",
    "    s = x.size()\n",
    "    assert n_dims > 1 and n_dims < len(s)\n",
    "    return x.view(*s[:-n_dims], -1)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"A layernorm module in the TF style (epsilon inside the square root).\"\n",
    "    def __init__(self, hidden, variance_epsilon=1e-12):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden))\n",
    "        self.beta  = nn.Parameter(torch.zeros(hidden))\n",
    "        self.variance_epsilon = variance_epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.gamma * x + self.beta\n",
    "\n",
    "class Time2Vec(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=1024):\n",
    "        super(Time2Vec,self).__init__()\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_dim, out_dim))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(out_dim))\n",
    "        self.F_sin = torch.sin\n",
    "        self.F_tanh = torch.tanh\n",
    "        self.F_relu = torch.relu\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        t : [batch_size, seg_num, 2 or 3] / 2 or 3 means start, end of boundary, (length of segment )\n",
    "        ----------------------\n",
    "        h : [batch_size, seg_num, feature]\n",
    "        \"\"\"\n",
    "        h = torch.matmul(t, self.w) + self.b\n",
    "        splited_h = torch.split(h, math.ceil(h.shape[1]/4), dim=1)\n",
    "        h = torch.cat([splited_h[0],\n",
    "                       self.F_sin(splited_h[1]),\n",
    "                       self.F_tanh(splited_h[2]),\n",
    "                       self.F_relu(splited_h[3])], dim=1)\n",
    "        return h\n",
    "        \n",
    "class BoundaryEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Boundary Embedding module to merge information among frames, position(boundary, time), etc.  \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(BoundaryEmbedding,self).__init__()\n",
    "        self.boundary_embed = Time2Vec(config['Time2Vec']['in_dim'], config['Time2Vec']['out_dim'])\n",
    "        self.norm = LayerNorm(config['Time2Vec']['out_dim'])\n",
    "\n",
    "    def forward(self, x, boundaries, add_length=True):\n",
    "        \"\"\"\n",
    "        x : [batch_size, seg_num, feature]\n",
    "        boundaries : [batch_size, seg_num, 2] / 2 means start, end of boundary\n",
    "        \"\"\"\n",
    "        if add_length :\n",
    "            segment_length = (boundaries[:,:,1] - boundaries[:,:,0]).unsqueeze(-1) # [batch_size, seg_num, 1]\n",
    "            boundaries = torch.cat((boundaries, segment_length), dim=-1) # [batch_size, seg_num, 3]\n",
    "        t = self.boundary_embed(boundaries) # [batch_size, seg_num, feature]\n",
    "        h = x + t\n",
    "        return self.norm(h)          \n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Dot-Product Self-Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(MultiHeadSelfAttention,self).__init__()\n",
    "        self.proj_q = nn.Linear(config['BERT']['hidden'], config['BERT']['hidden']) # W_query\n",
    "        self.proj_k = nn.Linear(config['BERT']['hidden'], config['BERT']['hidden']) # W_key \n",
    "        self.proj_v = nn.Linear(config['BERT']['hidden'], config['BERT']['hidden']) # W_value\n",
    "        self.n_heads = config['BERT']['head']\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x : [batch_size, seg_num, feature]\n",
    "        mask : \n",
    "        \"\"\"\n",
    "        # x : [ batch_size, seg_num, feature ]\n",
    "        q, k, v = self.proj_q(x), self.proj_k(x), self.proj_v(x)\n",
    "        # (projection) q, k ,v : [batch_size, seg_num, hidden ]\n",
    "        q, k ,v = [split_last(x, (self.n_heads, -1)).transpose(1,2) for x in [q,k,v]]\n",
    "        # (split) q, k, v : [batch_size, seg_num, head, w (= hidden/head) ]\n",
    "        # (transpose) q, k, v : [batch_size, head, seg_num, w] \n",
    "        scores = q @ k.transpose(-2, -1) / np.sqrt(k.size(-1))\n",
    "        # scores : [batch_size, head, seg_num, seg_num] \n",
    "\n",
    "        # TODO : masking\n",
    "        # if mask is not None:\n",
    "        #     mask = mask[:, None, None, :].float()\n",
    "        #     scores -= 10000.0 * (1.0 - mask)\n",
    "        \n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        # scores : [batch_size, head, seg_num, seg_num]\n",
    "        h = (scores @ v).transpose(1,2).contiguous()\n",
    "        # h : [batch_size, head, seg_num, w]\n",
    "        # (transpose) h : [batch_size, seg_num, head, w]\n",
    "        h = merge_last(h, 2)\n",
    "        # h : [batch_size, seg_num, hidden]\n",
    "        self.scores = scores\n",
    "        return h\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    FFN(Feed Forward Neural Networks) for each position\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(config['BERT']['hidden'], config['BERT']['hidden_ff'])\n",
    "        self.fc2 = nn.Linear(config['BERT']['hidden_ff'], config['BERT']['hidden'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(gelu(self.fc1(x)))              \n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BERT, self).__init__()\n",
    "        self.be = BoundaryEmbedding(config)\n",
    "        self.num_layers = config['BERT']['n_layers']\n",
    "        self.attn = MultiHeadSelfAttention(config)\n",
    "        self.proj = nn.Linear(config['BERT']['hidden'], config['BERT']['hidden'])\n",
    "        self.norm1 = LayerNorm(config['BERT']['hidden'])\n",
    "        self.pwff = PositionWiseFeedForward(config)\n",
    "        self.norm2 = LayerNorm(config['BERT']['hidden'])\n",
    "\n",
    "    def forward(self, x, boundaries, mask=None):\n",
    "        \"\"\"\n",
    "        x : [batch_size, num_segment, feature]\n",
    "        boundaries : [batch_size, num_segment, 2]\n",
    "        ------------------------\n",
    "        h : [batch_size, num_segment + 1, hidden ]\n",
    "        \"\"\"\n",
    "\n",
    "        h = self.be(x, boundaries, add_length=True)\n",
    "        for _ in range(self.num_layers):\n",
    "            h = self.attn(h, mask)\n",
    "            h = self.norm1(h + self.proj(h))\n",
    "            h = self.norm2(h + self.pwff(h))\n",
    "        return h        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ldk1FGo8qHcu"
   },
   "outputs": [],
   "source": [
    "class DomainConcatFC(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DomainConcatFC, self).__init__()\n",
    "        self.fc1 = nn.Linear(config['BERT']['hidden']*config['num_domain'],config['DomainConcatFC']['hidden'])\n",
    "        self.fc2 = nn.Linear(config['DomainConcatFC']['hidden'], config['BERT']['hidden'])\n",
    "\n",
    "    def forward(self, hidden_wave, hidden_spec):\n",
    "        \"\"\"\n",
    "        hidden_* : [batch_size, num_segment, feature]\n",
    "        \"\"\"\n",
    "        concat_feature = torch.cat((hidden_wave, hidden_spec), dim=-1) # [ batch_size, num_segment, 2 * feature ]\n",
    "        h = self.fc2(gelu(self.fc1(concat_feature)))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jHHeqOvhxT6"
   },
   "outputs": [],
   "source": [
    "# Deep InfoMax(DIM) \n",
    "# reference : https://github.com/rdevon/DIM\n",
    "# reference : https://github.com/DuaneNielsen/DeepInfomaxPytorch\n",
    "\n",
    "def raise_measure_error(measure):\n",
    "    supported_measures = ['GAN', 'JSD', 'X2', 'KL', 'RKL', 'DV', 'H2', 'W1']\n",
    "    raise NotImplementedError(\n",
    "        'Measure `{}` not supported. Supported: {}'.format(measure,\n",
    "                                                           supported_measures))\n",
    "\n",
    "def get_positive_expectation(p_samples, mesaure, average = True):\n",
    "    log_2 = math.log(2.)\n",
    "\n",
    "    if measure == 'GAN':\n",
    "        Ep = - F.softplus(-p_samples)\n",
    "    elif measure == 'JSD':\n",
    "        Ep = log_2 - F.softplus(-p_samples) \n",
    "    elif measure == 'X2':\n",
    "        Ep = p_samples ** 2\n",
    "    elif measure == 'KL':\n",
    "        Ep = p_samples\n",
    "    elif measure == 'RKL':\n",
    "        Ep = -torch.exp(-p_samples)\n",
    "    elif measure == 'DV':\n",
    "        Ep = p_samples\n",
    "    elif measure == 'H2':\n",
    "        Ep = 1. - torch.exp(-p_samples)\n",
    "    elif measure == 'W1':\n",
    "        Ep = p_samples\n",
    "    else:\n",
    "        raise_measure_error(measure)\n",
    "    \n",
    "    if average:\n",
    "        return Ep.mean()\n",
    "    else:\n",
    "        return Ep\n",
    "\n",
    "def get_negative_expectation(q_samples, measure, average = True):\n",
    "    log_2 = math.log(2.)\n",
    "\n",
    "    if measure == 'GAN':\n",
    "        Eq = F.softplus(-q_samples) + q_samples\n",
    "    elif measure == 'JSD':\n",
    "        Eq = F.softplus(-q_samples) + q_samples - log_2 \n",
    "    elif measure == 'X2':\n",
    "        Eq = -0.5 * ((torch.sqrt(q_samples ** 2) + 1.) ** 2)\n",
    "    elif measure == 'KL':\n",
    "        Eq = torch.exp(q_samples - 1.)\n",
    "    elif measure == 'RKL':\n",
    "        Eq = q_samples - 1.\n",
    "    elif measure == 'DV':\n",
    "        Eq = log_sum_exp(q_samples, 0) - math.log(q_samples.size(0))\n",
    "    elif measure == 'H2':\n",
    "        Eq = torch.exp(q_samples) - 1.\n",
    "    elif measure == 'W1':\n",
    "        Eq = q_samples\n",
    "    else:\n",
    "        raise_measure_error(measure)\n",
    "    \n",
    "    if average:\n",
    "        return Ep.mean()\n",
    "    else:\n",
    "        return Ep\n",
    "\n",
    "def generator_loss(q_samples, measure, loss_type=None):\n",
    "    \"\"\"Computes the loss for the generator of a GAN.\n",
    "    Args:\n",
    "        q_samples: fake samples.\n",
    "        measure: Measure to compute loss for.\n",
    "        loss_type: Type of loss: basic `minimax` or `non-saturating`.\n",
    "    \"\"\"\n",
    "    if not loss_type or loss_type == 'minimax':\n",
    "        return get_negative_expectation(q_samples, measure)\n",
    "    elif loss_type == 'non-saturating':\n",
    "        return -get_positive_expectation(q_samples, measure)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Generator loss type `{}` not supported. '\n",
    "            'Supported: [None, non-saturating, boundary-seek]')\n",
    "\n",
    "def fenchel_dual_loss(x, measure):\n",
    "    \"\"\"\n",
    "    x : [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    pos_mask = torch.eye(batch_size).to(x.device)\n",
    "    neg_mask = 1 - pos_mask\n",
    "\n",
    "    E_pos = get_positive_expectation(x, measure, average = False)\n",
    "    E_neg = get_negative_expectation(x, measure, average = False)\n",
    "\n",
    "    E_pos = (E_pos * pos_mask).sum() / pos_mask.sum()\n",
    "    E_neg = (E_neg * neg_mask).sum() / neg_mask.sum()\n",
    "    loss = E_neg - E_pos\n",
    "    return loss\n",
    "\n",
    "def info_nce_loss(x):\n",
    "    pass\n",
    "\n",
    "def donsker_varadhan_loss(x):\n",
    "    pass\n",
    "\n",
    "def compute_dim_loss(x, mode, measure):\n",
    "    if mode == 'fd':\n",
    "        return fenchel_dual_loss(x, measure)\n",
    "    if mode == 'nce':\n",
    "        return info_nce_loss(x)\n",
    "    if mode == 'dv':\n",
    "        return donsker_varadhan_loss(x)\n",
    "\n",
    "\n",
    "class GlobalDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    global discriminator of DIM.\n",
    "    ==============================\n",
    "    <input>\n",
    "    : global feature, G : [ batch_size, feature_dim ]\n",
    "    : local feature sequence, LS : [batch_size, seg_num, feature_dim]\n",
    "    ==============================\n",
    "    <output>\n",
    "    : boolean of global discriminator return, B ; [batch_size, seg_num]\n",
    "    ==============================    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(GlobalDiscriminator, self).__init__()\n",
    "        self.num_segment = config['num_segment']\n",
    "        self.layer_0 = nn.Linear(config['BERT']['hidden']*2, config['GlobalDiscriminator']['hidden'])\n",
    "        self.layer_1 = nn.Linear(config['GlobalDiscriminator']['hidden'], config['GlobalDiscriminator']['hidden_ns'])\n",
    "        self.layer_2 = nn.Linear(config['GlobalDiscriminator']['hidden_ns'] * self.num_segment, 1)\n",
    "\n",
    "    def forward(self, g, ls):\n",
    "        bs = g.shape[0]\n",
    "        h = torch.cat((ls, g.repeat(self.num_segment,1,1).transpose(1,0)), dim=-1) # [batch_size, num_segment, feature_dim * 2]\n",
    "        h = F.relu(self.layer_0(h)) # [batch_size, num_segment, GD_hidden]\n",
    "        h = F.relu(self.layer_1(h)) # [batch_size, num_segment,]\n",
    "        h = self.layer_2(h.view(bs, -1)) # [batch_size, num_segment * GD_hidden_ns] -> [batch_size, 1]\n",
    "        return h\n",
    "\n",
    "class LocalDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    local discriminator of DIM.\n",
    "    ==============================\n",
    "    <input>\n",
    "    : global feature, G : [ batch_size * num_segment, feature_dim ]\n",
    "    : local features, L : [ batch_size * num_segment, feature_dim ]\n",
    "    (option) index, I : [batch_size] or time_vector, tv : [batch_size, feature_dim]\n",
    "    ==============================\n",
    "    <output>\n",
    "    : boolean of local discrminator return, B : [batch_size * num_segment, 1]\n",
    "    ==============================    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(LocalDiscriminator, self).__init__()\n",
    "        self.layer_0 = nn.Linear(config['BERT']['hidden']*2, config['LocalDiscriminator']['hidden'])\n",
    "        self.layer_1 = nn.Linear(config['LocalDiscriminator']['hidden'], 1)\n",
    "\n",
    "    def forward(self,g, l, idx=None):\n",
    "        if idx:\n",
    "            pass\n",
    "        else:\n",
    "            h = torch.cat((g, l), dim=-1) # [batch_size * num_segment, 2 * feature_dim]\n",
    "            h = F.relu(self.layer_0(h)) # [batch_size * num_segment, LD_hidden ]\n",
    "            h = self.layer_1(h) # [batch_size * num_segment, 1]\n",
    "            return h\n",
    "\n",
    "class MaskDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    masked discriminator of DIM.\n",
    "    ==============================\n",
    "    <input>\n",
    "    : local feature, L : [ batch_size , num_segment , feature_dim ]\n",
    "    : origin feature, O : [ batch_size, num_segment , feature_dim ]\n",
    "    ==============================\n",
    "    <output>\n",
    "    : boolean of masked discriminator return, B : [batch_size , num_segment ]   \n",
    "    ==============================    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_0 = nn.Linear(config['BERT']['hidden']*2, config['MaskDiscriminator']['hidden'])\n",
    "        self.layer_1 = nn.Linear(config['MaskDiscriminator']['hidden'], 1)\n",
    "\n",
    "    def forward(self, ls, origins):\n",
    "        h = torch.cat((ls, origins), dim=-1) # [batch_size , num_segment , feature_dim * 2]\n",
    "        h = F.relu(self.layer_0(h)) # [batch_size, num_segment , MD_hidden]\n",
    "        h = self.layer_1(h) # [batch_size , num_segment, 1]\n",
    "        return h\n",
    "\n",
    "class PriorMatching(nn.Module):\n",
    "    \"\"\"\n",
    "    prior matching of DIM.\n",
    "    ==============================\n",
    "    <input>\n",
    "    : x : <global feature, G : [batch_size, feature_dim] >  or < prior, P : [ batch_size, feature_dim ]>\n",
    "    ==============================\n",
    "    <output>\n",
    "    : boolean of prior matching return, B : [batch_size] = True if prior, False if global feature  \n",
    "    ==============================    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_0 = nn.Linear(config['BERT']['hidden'], config['PriorMatching']['hidden'])\n",
    "        self.layer_1 = nn.Linear(config['PriorMatching']['hidden'], config['PriorMatching']['hidden'])\n",
    "        self.layer_2 = nn.Linear(config['PriorMatching']['hidden'], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.layer_0(x))\n",
    "        h = F.relu(self.layer_1(h))\n",
    "        return torch.sigmoid(self.layer_2(h))\n",
    "\n",
    "class MIBERT_Loss(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MIBERT_Loss, self).__init__()\n",
    "        self.GD = GlobalDiscriminator(config)\n",
    "        self.LD = LocalDiscriminator(config)\n",
    "        self.MD = MaskDiscriminator(config)\n",
    "        self.PM = PriorMatching(config)\n",
    "\n",
    "        self.alpha = config['alpha']\n",
    "        self.beta = config['beta']\n",
    "        self.gamma = config['gamma']\n",
    "        self.delta = config['delta']\n",
    "        self.num_segment = config['num_segment']\n",
    "\n",
    "    def forward(self, g, ls, ls_prime, origins):\n",
    "        \"\"\"\n",
    "        g : [batch_size, 1, feature]\n",
    "        ls : [batch_size, num_segment, feature]\n",
    "        ls_prime : [batch_size, num_segment, feature]\n",
    "        origins : [batch_Size, num_segment, feature]\n",
    "        \"\"\"\n",
    "        # g, ls = x[:,0:1,:], x[:,1:,:] # [batch_size, 1, feature], [batch_size, num_segment, feature]\n",
    "        \n",
    "        Ej = -F.softplus(-self.GD(g.squeeze(), ls)).mean()\n",
    "        Em = F.softplus(self.GD(g.squeeze(), ls_prime)).mean()\n",
    "        GLOBAL = (Em - Ej) * self.alpha\n",
    "\n",
    "        Ej = -F.softplus(-self.LD(g.repeat(1,self.num_segment,1 ), ls)).mean()\n",
    "        Em = F.softplus(self.LD(g.repeat(1, self.num_segment, 1), ls_prime)).mean()\n",
    "        LOCAL = (Em - Ej) * self.beta\n",
    "\n",
    "        Ej = -F.softplus(-self.MD(ls, origins)).mean()\n",
    "        Em = F.softplus(self.MD(ls_prime, origins)).mean()\n",
    "        MASK = (Em - Ej) * self.gamma\n",
    "\n",
    "        prior = torch.rand_like(g.squeeze())\n",
    "        term_a = torch.log(self.PM(prior)).mean()\n",
    "        term_b = torch.log(1.0 - self.PM(g.squeeze())).mean()\n",
    "        PRIOR = -( term_a + term_b ) * self.delta\n",
    "\n",
    "        return GLOBAL + LOCAL + MASK + PRIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzrpIEGBUsnR"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size' : 4,\n",
    "    \n",
    "    'data_block_threshold' : 10,\n",
    "    'sr' : 44100, \n",
    "    'FramizationCNN' : {\n",
    "        'feature' : 128,\n",
    "    },\n",
    "    'FraemwiseFC' : {\n",
    "        'fc1_in_dim' : 128,\n",
    "        'fc1_out_dim' : 1024,\n",
    "        'fc2_in_dim' : 1024,\n",
    "        'fc2_out_dim' : 1024,\n",
    "    },\n",
    "    'Time2Vec':{\n",
    "        'in_dim': 3,\n",
    "        'out_dim': 1024,\n",
    "    },\n",
    "    'num_segment' : 15,   \n",
    "    't2v_add_length' : True,\n",
    "    'BERT' : {\n",
    "        'hidden' : 1024,\n",
    "        'head' : 8,\n",
    "        'n_layers' : 3,\n",
    "        'hidden_ff' : 2048,\n",
    "    },\n",
    "    'num_domain' : 2,\n",
    "    'DomainConcatFC' : {\n",
    "        'hidden' : 3072\n",
    "    },\n",
    "    'init_segment' : 1024,\n",
    "    'measure' : 'JSD',\n",
    "    'mode' : 'fd',\n",
    "    'GlobalDiscriminator' : {\n",
    "    \t'hidden' : 1024,\n",
    "    \t'hidden_ns' : 64,\n",
    "    },\n",
    "    'LocalDiscriminator' : {\n",
    "    \t'hidden' : 1024,\n",
    "    },\n",
    "    'MaskDiscriminator' : {\n",
    "    \t'hidden' : 1024,\n",
    "    },\n",
    "    'PriorMatching' : {\n",
    "    \t'hidden' : 1024,\n",
    "    },\n",
    "    'alpha' : 0.3,\n",
    "    'beta' : 0.3,\n",
    "    'gamma' : 0.3,\n",
    "    'delta' : 0.1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "LX3f5x8Glphm",
    "outputId": "6f5bfe4c-13ad-408d-93c7-bba44f7cfa8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of wave :  torch.Size([4, 783360])\n",
      "shape of spectrogram :  torch.Size([4, 128, 1531])\n",
      "shape of frameCNN result :  torch.Size([4, 128, 1531])\n",
      "shape of wave FramewiseFC result :  torch.Size([4, 1531, 1024])\n",
      "shape of spec FramewiseFC result :  torch.Size([4, 1531, 1024])\n",
      "shape of segment pool result about wave frame :  torch.Size([4, 16, 1024])\n",
      "shape of segment pool result about spec frame :  torch.Size([4, 16, 1024])\n",
      "shape of boundaries tensor :  torch.Size([4, 16, 2])\n",
      "shape of BERT result about wave :  torch.Size([4, 16, 1024])\n",
      "shape of BERT result about spec :  torch.Size([4, 16, 1024])\n",
      "shape of DCFC result :  torch.Size([4, 16, 1024])\n",
      "tensor(1.3848, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# For debugging\n",
    "debug_info_lst = [1530, 150, 1529, 631]\n",
    "# masking\n",
    "def mel_filterbank(spectrogram, sr, n_fft, n_mels):\n",
    "    mel_filter = librosa.filters.mel(sr = sr , n_fft = n_fft, n_mels = n_mels)\n",
    "    return (mel_filter @ np.abs(spectrogram)**2)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "debug_wavs = [ np.random.normal(size=512*k) for k in debug_info_lst ]\n",
    "debug_specs = [mel_filterbank(librosa.stft(w), 44100, 2048, 128) for w in debug_wavs]\n",
    "\n",
    "W, w_real_len = tensorize_padding_batch(debug_wavs, mode=\"wave\")\n",
    "S, s_real_len = tensorize_padding_batch(debug_specs, mode=\"spec\")\n",
    "print(\"shape of wave : \",W.shape)\n",
    "print(\"shape of spectrogram : \", S.shape)\n",
    "\n",
    "frameCNN = FramizationCNN(config)\n",
    "FFC = FramewiseFC(config)\n",
    "\n",
    "framed_w = frameCNN(torch.unsqueeze(W, 1)) # unsqueeze : [batch_size, 1, wave_length]\n",
    "print(\"shape of frameCNN result : \", framed_w.shape)\n",
    "\n",
    "# transpose for fully-connected layer\n",
    "framed_w = torch.transpose(framed_w, 1,2)\n",
    "S = torch.transpose(S, 1,2)\n",
    "\n",
    "ffc_w = FFC(framed_w)\n",
    "ffc_s = FFC(S)\n",
    "\n",
    "print(\"shape of wave FramewiseFC result : \", ffc_w.shape)\n",
    "print(\"shape of spec FramewiseFC result : \", ffc_s.shape)\n",
    "\n",
    "boundaries = [\n",
    "    sorted(\n",
    "        [0, k*512/44100]+\n",
    "        [random.uniform(0, k * 512 / 44100) for sn in range(config['num_segment']-1)]\n",
    "        ) \n",
    "    for k in debug_info_lst\n",
    "]\n",
    "labels = [\n",
    "    [\n",
    "        random.randrange(0, config['num_segment']//2)\n",
    "        for _ in range(len(boundaries[idx])-1)\n",
    "    ]\n",
    "    for idx, _ in enumerate(debug_info_lst)\n",
    "]\n",
    "\n",
    "sp_w_frame = segment_pooling(ffc_w, boundaries,w_real_len, config) # [batch_size, num_segment, feature]\n",
    "sp_s_frame = segment_pooling(ffc_s, boundaries,s_real_len, config) \n",
    "\n",
    "boundaries = torch.tensor(boundaries)\n",
    "boundaries = torch.stack((boundaries[:,:-1] , boundaries[:,1:]), dim=-1) # [batch_size, num_segment, 2]\n",
    "\n",
    "# add init segment block to boundaries / segment_pooling frames \n",
    "init_segment = nn.Parameter(torch.randn(config['init_segment']))\n",
    "boundaries_tensor = torch.zeros(size = [config['batch_size'], config['num_segment']+1, 2])\n",
    "boundaries_tensor[:,1:,:] = boundaries # [batch_size, num_segment+1, 2]\n",
    "sp_w_frame = torch.cat((init_segment.repeat(config['batch_size'],1).unsqueeze(1), sp_w_frame), dim =1)\n",
    "sp_s_frame = torch.cat((init_segment.repeat(config['batch_size'],1).unsqueeze(1), sp_s_frame), dim =1)\n",
    "\n",
    "print('shape of segment pool result about wave frame : ', sp_w_frame.shape) # [batch_size, num_segment+1, feature]\n",
    "print('shape of segment pool result about spec frame : ', sp_s_frame.shape)\n",
    "print(\"shape of boundaries tensor : \", boundaries_tensor.shape)\n",
    "\n",
    "bert = BERT(config)\n",
    "h_w = bert(sp_w_frame, boundaries_tensor)\n",
    "h_s = bert(sp_s_frame, boundaries_tensor)\n",
    "\n",
    "print('shape of BERT result about wave : ', h_w.shape)\n",
    "print('shape of BERT result about spec : ', h_s.shape)\n",
    "\n",
    "dcfc = DomainConcatFC(config)\n",
    "\n",
    "h = dcfc(h_w, h_s)\n",
    "\n",
    "print('shape of DCFC result : ', h.shape)\n",
    "\n",
    "mb_loss = MIBERT_Loss(config)\n",
    "\n",
    "g = h[:,0:1,:]\n",
    "ls = h[:,1:,:]\n",
    "ls_prime = torch.cat((ls[1:], ls[0].unsqueeze(0)), dim=0)\n",
    "\n",
    "loss = mb_loss(g, ls, ls_prime, ls)\n",
    "\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
